# -*- coding: utf-8 -*-
"""Deployment .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11r3mQCbrmEIi9y9lNESNWSitAjJdjEPc

##Step-by-Step Deployment Using VSCode

###**1**. Initialize Function App using Python
"""

func init ArchiveBillingRecords --python
cd ArchiveBillingRecords
func new --name ArchiveOldRecords --template "Timer trigger" --authlevel "function"

# Commented out IPython magic to ensure Python compatibility.
!func init ArchiveBillingRecords --python
# %cd ArchiveBillingRecords
!func new --name ArchiveOldRecords --template "Timer trigger" --authlevel "function"

"""Youâ€™ll get a function.json with:"""

{
  "schedule": "0 0 2 * * *",  // Every day at 2 AM UTC
  "name": "mytimer",
  "type": "timerTrigger",
  "direction": "in"
}

"""###**2**. Install Required Libraries in Python"""

pip install azure-cosmos azure-storage-blob azure-data-tables
pip freeze > requirements.txt

"""###**3**.Configure Local Settings
Add connection strings in local.settings.json:
"""

{
  "IsEncrypted": false,
  "Values": {
    "AzureWebJobsStorage": "<storage-conn-string>",
    "CosmosDBConn": "<cosmos-conn-string>",
    "AzureWebJobsDashboard": "",
    "BlobContainerName": "cold-billing-data",
    "ArchiveTable": "BillingArchiveIndex"
  }
}

"""###**4**. Write Your Archival Logic in Python"""

import datetime, json
import azure.functions as func
from azure.cosmos import CosmosClient
from azure.storage.blob import BlobServiceClient
from azure.data.tables import TableServiceClient

def main(mytimer: func.TimerRequest) -> None:
    cosmos = CosmosClient.from_connection_string(os.environ['CosmosDBConn'])
    db = cosmos.get_database_client("billing")
    container = db.get_container_client("records")

    blob_service = BlobServiceClient.from_connection_string(os.environ["AzureWebJobsStorage"])
    blob_client = blob_service.get_container_client(os.environ["BlobContainerName"])

    table_service = TableServiceClient.from_connection_string(os.environ["AzureWebJobsStorage"])
    table_client = table_service.get_table_client(os.environ["ArchiveTable"])

    threshold = datetime.datetime.utcnow() - datetime.timedelta(days=90)

    for record in container.query_items(
        query="SELECT * FROM c WHERE c.timestamp < @date",
        parameters=[{"name": "@date", "value": threshold.isoformat()}],
        enable_cross_partition_query=True
    ):
        blob_name = f"{record['id']}.json"
        blob_client.upload_blob(blob_name, json.dumps(record), overwrite=True)

        table_client.upsert_entity({
            "PartitionKey": "BillingRecord",
            "RowKey": record["id"],
            "blob_uri": f"https://<storage>.blob.core.windows.net/{os.environ['BlobContainerName']}/{blob_name}"
        })

        container.delete_item(record, partition_key=record['partitionKey'])

"""###**5**. Deploy to Azure"""

func azure functionapp publish <your-function-app-name>

"""###**6**. Monitor in Azure Portal

Navigate to Function App > Functions > ArchiveOldRecords

View logs, set alerts, or add Application Insights for deeper telemetry.
"""